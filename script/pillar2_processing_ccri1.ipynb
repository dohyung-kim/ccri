{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "16kXoLnxLFkrgGcnkshrskpmHlBR5PQvq",
      "authorship_tag": "ABX9TyNOBYRPfAPEZPrxbIU9BRv/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dohyung-kim/ccri/blob/main/script/pillar2_processing_ccri1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8b-eFOCMSb6",
        "outputId": "7483cca6-be09-44ef-ef36-4996d30b3867",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from scipy.stats import gmean\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "0wpgb-1GLEuK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define function to remove outliers and find min max values to reduce skew\n",
        "def trim_outliers_iteratively(values, max_skew=2, max_kurtosis=3.5):\n",
        "    \"\"\"\n",
        "    Iteratively removes extreme min/max values until skewness <= 2 and kurtosis <= 3.5.\n",
        "    Returns the trimmed dataset along with the final min and max.\n",
        "    \"\"\"\n",
        "    values = values.dropna().values  # Ensure no NaNs\n",
        "    while True:\n",
        "        current_skew = skew(values)\n",
        "        current_kurtosis = kurtosis(values)\n",
        "\n",
        "        if abs(current_skew) <= max_skew and current_kurtosis <= max_kurtosis:\n",
        "            break  # Stop if conditions are met\n",
        "\n",
        "        # Remove min and max values\n",
        "        min_val, max_val = values.min(), values.max()\n",
        "        values = values[(values > min_val) & (values < max_val)]  # Trim extreme min/max\n",
        "\n",
        "    return values, values.min(), values.max()"
      ],
      "metadata": {
        "id": "zmLUzUaHjI7F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize and obtain min max value for P2 indicators"
      ],
      "metadata": {
        "id": "YSjAOckBaI7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define source and destination folder paths\n",
        "source_folder = \"/content/drive/MyDrive/\"\n",
        "destination_folder = \"/content/drive/MyDrive/CCRI/pillar2/\"\n",
        "\n",
        "# Get all copied CSV files\n",
        "csv_files = glob.glob(os.path.join(destination_folder, \"*.csv\"))\n",
        "\n",
        "# List of variables to reverse normalize\n",
        "reverse_columns = [\n",
        "    'P2_LSCED',\n",
        "    'P2_Birth_Attendant_Y15T19',\n",
        "    'P2_ED_CR_L2',\n",
        "    'P2_Immunization_DTP1',\n",
        "    'P2_Immunization_DTP3',\n",
        "    'P2_WASH_Drinking_Water',\n",
        "    'P2_WASH_Sanitation',\n",
        "    'P2_basic_hygiene',\n",
        "    'P2_electricity_access',\n",
        "    'P2_Social_Protection'\n",
        "]\n",
        "\n",
        "# Initialize an empty DataFrame for merged results\n",
        "merged_df = pd.DataFrame()\n",
        "\n",
        "for file in csv_files:\n",
        "    if os.path.basename(file) == \"P2_Merged_Normalized_avg.csv\":\n",
        "      continue\n",
        "    df = pd.read_csv(file)\n",
        "\n",
        "    if 'iso3' not in df.columns or 'value' not in df.columns:\n",
        "        continue  # Skip files missing required columns\n",
        "    # Normalize 'value' column\n",
        "    df = df[['iso3', 'value']].dropna()\n",
        "    # Apply iterative trimming\n",
        "    trimmed_values, min_trimmed, max_trimmed = trim_outliers_iteratively(df['value'])\n",
        "    # Normalize using final min/max\n",
        "    df['value_normalized'] = 10 * (df['value'] - min_trimmed) / (max_trimmed - min_trimmed)\n",
        "\n",
        "    # Ensure values are within [0,10]\n",
        "    df['value_normalized'] = np.clip(df['value_normalized'], 0, 10)\n",
        "    df['min'] = min_trimmed\n",
        "    df['max'] = max_trimmed\n",
        "\n",
        "    # Extract filename for column naming\n",
        "    filename = os.path.basename(file).replace(\".csv\", \"\")\n",
        "\n",
        "    # Reverse normalization for specific columns\n",
        "    if filename in reverse_columns:\n",
        "        df['value_normalized'] = 10 - df['value_normalized']  # Reverse normalize\n",
        "\n",
        "    # Rename column\n",
        "    df.rename(columns={'value_normalized': filename + '_value_normalized'}, inplace=True)\n",
        "    df.rename(columns={'min': filename + '_min'}, inplace=True)\n",
        "    df.rename(columns={'max': filename + '_max'}, inplace=True)\n",
        "\n",
        "    print(f\"processed : {filename} | min: {min_trimmed} | max: {max_trimmed}\" )\n",
        "\n",
        "    # Merge with the main DataFrame (use suffixes to avoid column name conflicts)\n",
        "    if merged_df.empty:\n",
        "        merged_df = df[['iso3', filename + '_value_normalized', filename + '_min', filename + '_max']]\n",
        "    else:\n",
        "        merged_df = merged_df.merge(df[['iso3', filename + '_value_normalized', filename + '_min', filename + '_max']],\n",
        "                                     on='iso3', how='left', suffixes=('', f'_{filename}'))\n",
        "\n",
        "# Filter columns that end with '_value_normalized'\n",
        "pillar2_columns = [col for col in merged_df.columns if col.endswith('_value_normalized')]\n",
        "\n",
        "# Compute the average across all '_value_normalized' columns (ignoring NaNs)\n",
        "merged_df[\"P2_arithmetic_avg\"] = merged_df[pillar2_columns].apply(np.nanmean, axis=1)\n",
        "\n",
        "# Calculate geometric average\n",
        "merged_df[\"P2_geometric_avg\"] = merged_df[pillar2_columns].apply(\n",
        "    lambda x: gmean(x[~np.isnan(x)] + 1e-10) if np.any(~np.isnan(x)) else np.nan, axis=1\n",
        ")\n",
        "\n",
        "# Save the final merged dataset\n",
        "output_file = os.path.join(destination_folder, \"P2_Merged_Normalized_avg.csv\")\n",
        "merged_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Processed data saved to {output_file}\")\n"
      ],
      "metadata": {
        "id": "nobVHJi6Wpvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ce64833-37f8-442e-8b98-8989281c7703"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed : P2_WASH_Drinking_Water | min: 35.11656657990258 | max: 100.0\n",
            "processed : P2_WASH_Sanitation | min: 9.336216099 | max: 100.0\n",
            "processed : P2_LSCED | min: 0.0267945 | max: 72.58609\n",
            "processed : P2_Nutrition_Wasting | min: 0.1 | max: 22.7\n",
            "processed : P2_Nutrition_Stunting_Modeled | min: 1.2 | max: 56.5\n",
            "processed : P2_Child_Mortality | min: 0.404633951697431 | max: 30.2232985695993\n",
            "processed : P2_Immunization_DTP1 | min: 45.0 | max: 98.0\n",
            "processed : P2_Immunization_DTP3 | min: 35.0 | max: 98.0\n",
            "processed : P2_PT_Labor | min: 0.3 | max: 41.5\n",
            "processed : P2_Learning_Poverty | min: 2.330512762069702 | max: 98.50421142578124\n",
            "processed : P2_ED_CR_L2 | min: 5.8079791 | max: 99.800003\n",
            "processed : P2_Birth_Attendant_Y15T19 | min: 25.4 | max: 100.0\n",
            "processed : P2_Child_poverty | min: 2.6400771141052246 | max: 83.46825408935547\n",
            "processed : P2_Child_Marriage | min: 0.0 | max: 76.3\n",
            "processed : P2_food_poverty | min: 0.0 | max: 70.1\n",
            "processed : P2_Social_Protection | min: 0.0 | max: 100.0\n",
            "processed : P2_basic_hygiene | min: 3.440188936 | max: 100.0\n",
            "processed : P2_electricity_access | min: 9.3 | max: 100.0\n",
            "Processed data saved to /content/drive/MyDrive/CCRI/pillar2/P2_Merged_Normalized_avg.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O_zb7KwtrbT3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}